# 基础知识
## 概念
使用队列来通信 的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：  
![image](https://github.com/user-attachments/assets/be4db8cc-e770-4b55-87b0-2134991c898e)

通常说的消息队列，简称MQ（Message Queue） ，它其实就指消息中间件，当前业界比较流行的开源消息中间件包括：RabbitMQ、RocketMQ、Kafka。  

## 应用场景
应用解耦  
流量削峰  
异步处理  
消息通讯  
日志处理 

## 消息可靠性(本质是上ack机制)
三个阶段：  
1）生产者可靠性:同步、异步、事务(确认机制)
2）存储端可靠性:持久化（同步、异步刷盘）
3）消费端可靠性：执行完业务逻辑才响应ack

## 消息有序性
1）全局有序：一个topic，只有一个partition  
2）局部有序：消息发送按照partition key划分，同一个key的发送到同一个partition

## 重复消费问题
1）幂等性
2）过滤

## 消息积压问题
1）是否是bug
2）扩容：增加partition和consumer机器
3）临时queue处理，先缓存到queue中，处理完后再切回去

## 技术选型

| |Kafka| RocketMQ| RabbitMQ|
|----|-----|-----|-------|
|单机吞吐量|17.3w/s|11.6w/s|2.6w/s（消息做持久化）|
|开发语言|Scala/Java|Java|Erlang|
|主要维护者|Apache|Alibaba|Mozilla/Spring|
|订阅形式|基于topic，按照topic进行正则匹配的发布订阅模式|基于topic/messageTag，按照消息类型、属性进行正则匹配的发布订阅模式|提供了4种：direct, topic ,Headers和fanout。fanout就是广播模式
|持久化|支持大量堆积|支持大量堆积|支持少量堆积|
|顺序消息|支持|支持|不支持|
|集群方式|天然的Leader-Slave，无状态集群，每台服务器既是Master也是Slave|常用 多对’Master-Slave’ 模式，开源版本需手动切换Slave变成Master|支持简单集群，'复制’模式，对高级集群模式支持不好。|
|性能稳定性|较差|一般|好|

## 高可用
kafka高可用：  
1）集群部署：多broker
2）topic划分多partition，partition分布在多个broker上
3）每个partiton有对应的leader和follower（副本形式）,leader同步给follower，leader挂，follower可以切换成leader

## 一致性问题
事务消息  

## 开放问题
设计一个消息队列  
这个问题面试官主要考察三个方面的知识点：  
你有没有对消息队列的架构原理比较了解  
考察你的个人设计能力  
考察编程思想，如什么高可用、可扩展性、幂等等等。  

遇到这种设计题，大部分人会很蒙圈，因为平时没有思考过类似的问题。大多数人平时埋头增删改查，不去思考框架背后的一些原理。有很多类似的问题，比如让你来设计一个 Dubbo 框架，或者让你来设计一个MyBatis 框架，你会怎么思考呢？  
回答这类问题，并不要求你研究过那技术的源码，你知道那个技术框架的基本结构、工作原理即可。设计一个消息队列，我们可以从这几个角度去思考：  
![image](https://github.com/user-attachments/assets/898f12a0-f161-48d1-9311-3fa8c4c18b7e)


首先是消息队列的整体流程，producer发送消息给broker，broker存储好，broker再发送给consumer消费，consumer回复消费确认等。  
producer发送消息给broker，broker发消息给consumer消费，那就需要两次RPC了，RPC如何设计呢？可以参考开源框架Dubbo，你可以说说服务发现、序列化协议等等  
broker考虑如何持久化呢，是放文件系统还是数据库呢，会不会消息堆积呢，消息堆积如何处理呢。  
消费关系如何保存呢？ 点对点还是广播方式呢？广播关系又是如何维护呢？zk还是config server  
消息可靠性如何保证呢？如果消息重复了，如何幂等处理呢？  
消息队列的高可用如何设计呢？ 可以参考Kafka的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。  
消息事务特性，与本地业务同个事务，本地消息落库;消息投递到服务端，本地才删除；定时任务扫描本地消息库，补偿发送。  
MQ得伸缩性和可扩展性，如果消息积压或者资源不够时，如何支持快速扩容，提高吞吐？可以参照一下 Kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了吗。  


## 参考链接
https://juejin.cn/post/7088909199475736612
