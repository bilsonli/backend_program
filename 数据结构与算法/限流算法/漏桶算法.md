# 代码实现

```
type LeakyBucket struct {
	rate int64 //处理请求的速率
	capacity int64 //桶的最大容量
	last time.Time //桶中最后一个排队请求被处理的时间
	mu sync.Mutex
}

func (t *LeakyBucket) Limit(ctx context.Context) (time.Duration, error) {
	//这里进行加锁，保证每个请求按顺序依次处理
	t.mu.Lock()
	defer t.mu.Unlock()
	
	now := time.Now().UnixNano() //当前时间的纳秒数
	if now < t.last {
		// 说明已经有请求在排队了，那么新请求进来排队后被处理的时间就是rate后
		t.last += t.rate
	} else {
		// 说明为桶为空，也许是初始状态，也许是所有的请求都被处理完了.
		
	var offset int64 //代表等待处理该请求的时间需要等待多久
		delta := now - state.Last // 代表当前时间距离上次处理请求的时间过了多久
		if delta < t.rate {
	//说明还没有到下次处理请求的时间，则需要等待offset后才能到
			offset = t.rate - delta
		}
	//如果delta > t.rate 说明当前时间距离上次处理请求的时间已经超过了rate，offset为0，新的请求就应该被马上处理
		t.last = now + offset //更新该请求应该被处理的时间
	}
	
	wait := t.last - now //计算桶是否已经满了
	if wait/t.rate > t.capacity {
	//桶满了，返回error，调用者根据需要是直接丢弃还是等待wait长的时间。一般是直接丢弃。
	
	t.last = now - offset //因为这里要丢弃该请求，所有要保持新请求排队前的状态
		return time.Duration(wait), ErrLimitExhausted
	}
	
	//排队成功，返回要等待的时间给调用者，让调用者sleep进行阻塞就能实现按rate的速率处理请求了
	return time.Duration(wait), nil
}
```
